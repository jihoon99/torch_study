{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b529636-9d37-46da-9eb2-c3e51c8d7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchtext\n",
    "version = list(map(int, torchtext.__version__.split('.')))\n",
    "if version[0] <= 0 and version[1] < 9:\n",
    "    from torchtext import data, datasets\n",
    "else:\n",
    "    from torchtext.legacy import data, datasets\n",
    "\n",
    "PAD, BOS, EOS = 1, 2, 3\n",
    "# PAD의 번호는 1, BOS는 2, EOS는 3인가보네\n",
    "\n",
    "\n",
    "class DataLoader():\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_fn=None,\n",
    "                 valid_fn=None,\n",
    "                 exts=None,\n",
    "                 batch_size=64,\n",
    "                 device='cpu',\n",
    "                 max_vocab=99999999,\n",
    "                 max_length=255,\n",
    "                 fix_length=None,\n",
    "                 use_bos=True,\n",
    "                 use_eos=True,\n",
    "                 shuffle=True,\n",
    "                 dsl=False\n",
    "                 ):\n",
    "\n",
    "        super(DataLoader, self).__init__()\n",
    "\n",
    "        # Field -> fields -> TabularDataset -> build_vocab -> Bucket\n",
    "\n",
    "        # src와 tgt가 각각 있는 이유는, 파일이 각각 있었기 때문이다.\n",
    "            # torchtext.data.Field\n",
    "        self.src = data.Field(\n",
    "            sequential=True,\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=True,\n",
    "            fix_length=fix_length, # None\n",
    "            init_token='<BOS>' if dsl else None, # dsl : dure learning할때 필요한것. 지금은 None이라고 보면 됨.\n",
    "            eos_token='<EOS>' if dsl else None,\n",
    "        )\n",
    "\n",
    "        self.tgt = data.Field(\n",
    "            sequential=True,\n",
    "            use_vocab=True,\n",
    "            batch_first=True,\n",
    "            include_lengths=True,\n",
    "            fix_length=fix_length,\n",
    "            init_token='<BOS>' if use_bos else None, # True .. learning에서는 필요 없고, 생성자 할때만 필요함(?)\n",
    "            eos_token='<EOS>' if use_eos else None,\n",
    "        )\n",
    "\n",
    "        if train_fn is not None and valid_fn is not None and exts is not None:\n",
    "            # TranslationDataset는 밑에 정의 되어있습니다.\n",
    "            train = TranslationDataset(\n",
    "                path=train_fn, # train file path\n",
    "                exts=exts, # en,ko path가 튜플로 들어가 있음.\n",
    "                fields=[('src', self.src), ('tgt', self.tgt)], # 사용할 필드 명\n",
    "                max_length=max_length\n",
    "            )\n",
    "            valid = TranslationDataset(\n",
    "                path=valid_fn,\n",
    "                exts=exts,\n",
    "                fields=[('src', self.src), ('tgt', self.tgt)],\n",
    "                max_length=max_length,\n",
    "            )\n",
    "\n",
    "            # bucketIterator가 하는 일을 실제 데이터를 가지고 와서. -> pad까지 체운 형태로 만들고\n",
    "            # 미니배치 단위로 만들어주는 역할을 한다.\n",
    "            # https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.BucketIterator\n",
    "            self.train_iter = data.BucketIterator(\n",
    "                train,\n",
    "                batch_size=batch_size,\n",
    "                device='cuda:%d' % device if device >= 0 else 'cpu',\n",
    "                shuffle=shuffle,\n",
    "                sort_key=lambda x: len(x.tgt) + (max_length * len(x.src)), # ?????????????? what's x?\n",
    "                sort_within_batch=True,\n",
    "            )\n",
    "\n",
    "            self.valid_iter = data.BucketIterator(\n",
    "                valid,\n",
    "                batch_size=batch_size,\n",
    "                device='cuda:%d' % device if device >= 0 else 'cpu',\n",
    "                shuffle=False,\n",
    "                sort_key=lambda x: len(x.tgt) + (max_length * len(x.src)),\n",
    "                sort_within_batch=True,\n",
    "            )\n",
    "\n",
    "            self.src.build_vocab(train, max_size=max_vocab)\n",
    "                # construct the vocab object for this field from one or more datasets.\n",
    "                # https://torchtext.readthedocs.io/en/latest/data.html\n",
    "                # it's word2idx : 어떤 단어가 몇번째 인덱스로 맵핑되는지.\n",
    "            self.tgt.build_vocab(train, max_size=max_vocab)\n",
    "\n",
    "    def load_vocab(self, src_vocab, tgt_vocab):\n",
    "        self.src.vocab = src_vocab\n",
    "        self.tgt.vocab = tgt_vocab\n",
    "\n",
    "\n",
    "# torchtext에는 maxlen을 잘라주는게 없어서 customizing했어.\n",
    "class TranslationDataset(data.Dataset):\n",
    "    \"\"\"Defines a dataset for machine translation.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return data.interleave_keys(len(ex.src), len(ex.trg))\n",
    "\n",
    "    def __init__(self, path, exts, fields, max_length=None, **kwargs):\n",
    "        \"\"\"Create a TranslationDataset given paths and fields.\n",
    "\n",
    "        Arguments:\n",
    "            path: Common prefix of paths to the data files for both languages.\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            Remaining keyword arguments: Passed to the constructor of\n",
    "                data.Dataset.\n",
    "        \"\"\"\n",
    "        if not isinstance(fields[0], (tuple, list)):\n",
    "            fields = [('src', fields[0]), ('trg', fields[1])]\n",
    "\n",
    "        if not path.endswith('.'):\n",
    "            path += '.'\n",
    "\n",
    "        src_path, trg_path = tuple(os.path.expanduser(path + x) for x in exts)\n",
    "\n",
    "        examples = []\n",
    "        with open(src_path, encoding='utf-8') as src_file, open(trg_path, encoding='utf-8') as trg_file:\n",
    "            for src_line, trg_line in zip(src_file, trg_file):\n",
    "                src_line, trg_line = src_line.strip(), trg_line.strip()\n",
    "                # max_length가 있을 경우에는 작업을 해줌.\n",
    "                if max_length and max_length < max(len(src_line.split()), len(trg_line.split())):\n",
    "                    continue\n",
    "                if src_line != '' and trg_line != '':\n",
    "                    examples += [data.Example.fromlist([src_line, trg_line], fields)]\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import sys\n",
    "#     loader = DataLoader(\n",
    "#         sys.argv[1],\n",
    "#         sys.argv[2],\n",
    "#         (sys.argv[3], sys.argv[4]),\n",
    "#         batch_size=128\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    loader = DataLoader(\n",
    "        config.train,                           # Train file name except extention, which is language. \n",
    "        config.valid,                           # Validation file name except extension.\n",
    "        (config.lang[:2], config.lang[-2:]),    # Source and target language. // 예) en, ko -> enko로 등록을 해야함.\n",
    "        batch_size=config.batch_size,\n",
    "        device=-1,                              # Lazy loading\n",
    "        max_length=config.max_length,           # Loger sequence will be excluded.\n",
    "        dsl=False,                              # Turn-off Dual-supervised Learning mode.\n",
    "    )\n",
    "\n",
    "    '''\n",
    "\n",
    "#     print(len(loader.src.vocab))\n",
    "#     print(len(loader.tgt.vocab))\n",
    "\n",
    "#     for batch_index, batch in enumerate(loader.train_iter):\n",
    "#         print(batch.src)\n",
    "#         print(batch.tgt)\n",
    "\n",
    "#         if batch_index > 1:\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2356d10-0d8c-45cd-acf1-c4911c6f3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_train = '/Users/rainism/Desktop/grad/torch_study/transformer/data/corpus.shuf.train.tok.bpe'\n",
    "config_valid = '/Users/rainism/Desktop/grad/torch_study/transformer/data/corpus.shuf.valid.tok.bpe'\n",
    "lang = 'enko'\n",
    "configBatchSize = 160\n",
    "device = -1\n",
    "configMaxLength = 64\n",
    "dsl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e887b66b-bc01-4201-b1c0-62188d998c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(config_train, config_valid, (lang[:2], lang[-2:]),\n",
    "                    batch_size = configBatchSize,\n",
    "                    device = device,\n",
    "                    max_length = configMaxLength,\n",
    "                    dsl = False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ce91a4-6c4b-4361-bae1-bdbd109896fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23776"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader.src.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f75f720c-8bf1-41e8-9545-4a7566db1f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([160, 25])\n",
      "torch.Size([160, 37])\n",
      "torch.Size([160, 14])\n",
      "torch.Size([160, 60])\n",
      "torch.Size([160, 48])\n",
      "torch.Size([160, 18])\n",
      "torch.Size([160, 48])\n",
      "torch.Size([160, 29])\n",
      "torch.Size([160, 11])\n",
      "torch.Size([160, 21])\n",
      "torch.Size([160, 42])\n",
      "torch.Size([160, 8])\n",
      "torch.Size([160, 16])\n",
      "torch.Size([160, 31])\n",
      "torch.Size([160, 40])\n",
      "torch.Size([160, 28])\n",
      "torch.Size([160, 22])\n",
      "torch.Size([160, 32])\n",
      "torch.Size([160, 14])\n",
      "torch.Size([160, 18])\n",
      "torch.Size([160, 12])\n",
      "torch.Size([160, 53])\n",
      "torch.Size([160, 46])\n",
      "torch.Size([160, 11])\n",
      "torch.Size([160, 42])\n",
      "torch.Size([160, 40])\n",
      "torch.Size([160, 21])\n",
      "torch.Size([160, 13])\n",
      "torch.Size([160, 9])\n",
      "torch.Size([160, 20])\n",
      "torch.Size([160, 10])\n",
      "torch.Size([160, 33])\n",
      "torch.Size([160, 19])\n",
      "torch.Size([160, 11])\n",
      "torch.Size([160, 28])\n",
      "torch.Size([160, 64])\n",
      "torch.Size([160, 30])\n",
      "torch.Size([160, 55])\n",
      "torch.Size([160, 59])\n",
      "torch.Size([160, 8])\n",
      "torch.Size([160, 35])\n",
      "torch.Size([160, 26])\n",
      "torch.Size([160, 13])\n",
      "torch.Size([160, 17])\n",
      "torch.Size([160, 62])\n",
      "torch.Size([160, 45])\n",
      "torch.Size([160, 43])\n",
      "torch.Size([160, 9])\n",
      "torch.Size([160, 20])\n",
      "torch.Size([160, 54])\n",
      "torch.Size([160, 37])\n",
      "torch.Size([160, 15])\n",
      "torch.Size([160, 47])\n",
      "torch.Size([160, 36])\n",
      "torch.Size([160, 34])\n",
      "torch.Size([160, 15])\n",
      "torch.Size([160, 19])\n",
      "torch.Size([160, 15])\n",
      "torch.Size([160, 51])\n",
      "torch.Size([160, 47])\n",
      "torch.Size([160, 12])\n",
      "torch.Size([160, 24])\n",
      "torch.Size([160, 10])\n",
      "torch.Size([160, 43])\n",
      "torch.Size([160, 41])\n",
      "torch.Size([160, 12])\n",
      "torch.Size([160, 35])\n",
      "torch.Size([160, 7])\n",
      "torch.Size([160, 41])\n",
      "torch.Size([160, 14])\n",
      "torch.Size([160, 31])\n",
      "torch.Size([160, 44])\n",
      "torch.Size([160, 19])\n",
      "torch.Size([160, 22])\n",
      "torch.Size([160, 38])\n",
      "torch.Size([160, 18])\n",
      "torch.Size([160, 50])\n",
      "torch.Size([160, 39])\n",
      "torch.Size([160, 29])\n",
      "torch.Size([160, 17])\n",
      "torch.Size([160, 16])\n",
      "torch.Size([160, 34])\n",
      "torch.Size([160, 46])\n",
      "torch.Size([160, 38])\n",
      "torch.Size([160, 10])\n",
      "torch.Size([160, 51])\n",
      "torch.Size([160, 24])\n",
      "torch.Size([160, 23])\n",
      "torch.Size([160, 39])\n",
      "torch.Size([160, 58])\n",
      "torch.Size([160, 33])\n",
      "torch.Size([160, 36])\n",
      "torch.Size([160, 52])\n",
      "torch.Size([160, 26])\n",
      "torch.Size([160, 13])\n",
      "torch.Size([160, 56])\n",
      "torch.Size([160, 44])\n",
      "torch.Size([160, 16])\n",
      "torch.Size([160, 49])\n",
      "torch.Size([160, 27])\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for batch_index, batch in enumerate(loader.train_iter):\n",
    "    print(batch.src[0].shape)\n",
    "    cnt += 1\n",
    "    if cnt == 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8a1bfa-3039-4690-a2e4-e6fa6e965425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 160]\n",
       "\t[.src]:('[torch.LongTensor of size 160x27]', '[torch.LongTensor of size 160]')\n",
       "\t[.tgt]:('[torch.LongTensor of size 160x54]', '[torch.LongTensor of size 160]')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7414437d-987d-45c8-8290-541d6ffd613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁▁She ▁▁turned ▁▁on ▁▁her ▁▁computer ▁▁and ▁▁went ▁▁to ▁▁E lla ▁&apos;s ▁website ▁.\n",
      " ▁▁줄 리아 ▁가 ▁▁그녀 ▁의 ▁▁컴퓨터 ▁로 ▁▁엘라 ▁의 ▁▁웹 ▁사이트 ▁에 ▁▁들어 갔 ▁어 ▁.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# [os.path.expanduser(config_train + x) for x in ('.' + lang[:2], '.'+lang[-2:])]\n",
    "src_path, trg_path = ['/Users/rainism/Desktop/grad/torch_study/transformer/data/corpus.shuf.train.tok.bpe.en',\n",
    "                         '/Users/rainism/Desktop/grad/torch_study/transformer/data/corpus.shuf.train.tok.bpe.ko']\n",
    "\n",
    "examples = []\n",
    "with open(src_path, encoding= 'utf-8') as src_file, open(trg_path, encoding = 'utf-8') as trg_file:\n",
    "    for src_line, trg_line in zip(src_file, trg_file):\n",
    "        print(src_line, trg_line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef8655c7-46a8-495f-addd-790b8de04900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "loss_weight = torch.ones(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69f92565-3ec3-4f19-bd92-418724f8c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weight[1] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cced72e-9438-4650-8180-7a97d82d21a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d0262-394d-4eeb-a098-5c01c2970a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
