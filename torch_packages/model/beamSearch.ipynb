{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a5d8a7-e309-405f-9e29-6078acdef90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c86a4d6-623f-4ea2-8775-40a3f67266b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 5\n",
    "max_length = 50\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd091b1-9841-4677-9889-728149af64ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_indice = [tensor([1, 1, 1, 1, 1])]\n",
      "beam_indice = [tensor([-1, -1, -1, -1, -1])]\n",
      "cumulative_probs = [tensor([0., -inf, -inf, -inf, -inf])]\n",
      "masks = [tensor([False, False, False, False, False])]\n",
      "--------------------------------------------\n",
      "prev_state_0 {'init_status': None, 'batch_dim_index': 0}\n",
      "prev_state_1 {'init_status': None, 'batch_dim_index': 0}\n"
     ]
    }
   ],
   "source": [
    "word_indice = [torch.LongTensor(beam_size).zero_().to(device)+1]\n",
    "print(f'word_indice = {word_indice}')\n",
    "beam_indice = [torch.LongTensor(beam_size).zero_().to(device)-1]\n",
    "print(f'beam_indice = {beam_indice}')\n",
    "cumulative_probs = [torch.FloatTensor([.0] + [-float('inf')] * (beam_size - 1)).to(device)]\n",
    "print(f'cumulative_probs = {cumulative_probs}')\n",
    "masks = [torch.BoolTensor(beam_size).zero_().to(device)]\n",
    "print(f'masks = {masks}')\n",
    "\n",
    "print('--------------------------------------------')\n",
    "\n",
    "prev_status = {}\n",
    "batch_dims = {}\n",
    "prev_status_config = {\n",
    "    'prev_state_0': {                   # input에 해당하는 state\n",
    "        'init_status': None,\n",
    "        'batch_dim_index': 0,\n",
    "    },\n",
    "    'prev_state_1': {                   # 첫번째 블락을 통과한 state\n",
    "        'init_status': None,\n",
    "        'batch_dim_index': 0,\n",
    "    }}\n",
    "\n",
    "for prev_status_name, each_config in prev_status_config.items():\n",
    "    print(prev_status_name, each_config)\n",
    "    init_status = each_config['init_status']\n",
    "    batch_dim_index = each_config['batch_dim_index']\n",
    "    if init_status is not None:\n",
    "        prev_status[prev_status_name] = torch.cat([init_status]*beam_size, dim = batch_dim_index)\n",
    "    else:\n",
    "        prev_status[prev_status_name] = None\n",
    "    batch_dims[prev_status_name] = batch_dim_index\n",
    "current_time_step = 0\n",
    "done_cnt = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e0e7481-dbc4-4f7a-b1e3-d42653b9cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = word_indice[-1].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867c52ed-d5f7-4db8-af94-51bbbda4dc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54909af8-571d-43a3-beff-4f33510eddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_state_0': None, 'prev_state_1': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21f93f1e-3380-44fa-9adc-732e14bf1e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fab_input = [torch.tensor([0,0,0,0,0]).unsqueeze(-1), torch.tensor([1,0,0,0,0]).unsqueeze(-1)]\n",
    "torch.cat(fab_input, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a292ba-dd46-4ad0-8fac-febef65e28bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df8c73bc-5705-4a2a-80eb-e837de8d3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import simple_nmt.data_loader as data_loader\n",
    "\n",
    "LENGTH_PENALTY = .2\n",
    "MIN_LENGTH = 5\n",
    "\n",
    "\n",
    "class SingleBeamSearchBoard():\n",
    "    '''\n",
    "    From Board\n",
    "        - input : x_t\n",
    "        - last hidden : h_t_1\n",
    "        - last cell : c_t_1\n",
    "        - last hidden_tilde : h_tilde_t_1\n",
    "    \n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,\n",
    "        prev_status_config, # Fake minibatch를 만들기 위해선, input, hidden, cell, hidden_tilde가 필요함. 이게 prev_status_config에 들어감.// type은 dict의 dict\n",
    "        beam_size=5,\n",
    "        max_length=255,\n",
    "    ):\n",
    "        '''\n",
    "        init에 previous_status를 저장함. -> prev_status\n",
    "        \n",
    "\n",
    "        '''\n",
    "        self.beam_size = beam_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # To put data to same device.\n",
    "        self.device = device\n",
    "        # Inferred word index for each time-step. For now, initialized with initial time-step. 첫번째니까 빔 사이즈 만큼 모두 BOS가 들어가야함.\n",
    "        self.word_indice = [torch.LongTensor(beam_size).zero_().to(self.device) + 1]\n",
    "            # [tensor([0,0,0,0,0])]\n",
    "            # 추후에 tensor([1,0,0,0,0]) 이런게 쌓임.\n",
    "        # Beam index for selected word index, at each time-step. 빔 사이즈 만큼 -1을 채워넣은 텐서\n",
    "        self.beam_indice = [torch.LongTensor(beam_size).zero_().to(self.device) - 1]\n",
    "        # Cumulative log-probability for each beam. \n",
    "        self.cumulative_probs = [torch.FloatTensor([.0] + [-float('inf')]*(beam_size - 1)).to(self.device)]\n",
    "            # 처음 cumulative_probs에서 [0, -inf, -inf, -inf, -inf]로 하고싶음. 왜냐면 BOS는 확정적인거라 1의 확률을 갖는데 log(BOS) = 0임.\n",
    "            # 가지가 분할하기 전에는 한개의 확률만 갖으므로 나머지는 -inf로 채움.\n",
    "            # 첫번째 빔에서(0)만 5개의 후보가 뽑힐거야\n",
    "        # 1 if it is done else 0\n",
    "        self.masks = [torch.BoolTensor(beam_size).zero_().to(self.device)]\n",
    "            # 0이면 진행, 1(EOS)면 끝.\n",
    "\n",
    "        # We don't need to remember every time-step of hidden states:\n",
    "        #       prev_hidden, prev_cell, prev_h_t_tilde\n",
    "        # What we need is remember just last one.\n",
    "\n",
    "        #-------------------- 맨처음 세팅해줘야 하는것 -----------------------\n",
    "        self.prev_status = {}\n",
    "        self.batch_dims = {}\n",
    "        for prev_status_name, each_config in prev_status_config.items():\n",
    "            init_status = each_config['init_status'] # 바로 전의 state을 가져오고\n",
    "            batch_dim_index = each_config['batch_dim_index'] # 배치 인덱스를 가져와\n",
    "            if init_status is not None:\n",
    "                self.prev_status[prev_status_name] = torch.cat([init_status] * beam_size,\n",
    "                                                               dim=batch_dim_index)\n",
    "                    # s2s - hidden, cell :  [L, B*beam_size, H] 여기서 B는 1임.\n",
    "            else:\n",
    "                self.prev_status[prev_status_name] = None\n",
    "                    # s2s - h_tilde : [B*beam, 1, hidden]\n",
    "            self.batch_dims[prev_status_name] = batch_dim_index\n",
    "                # s2s - {hidden_state : 1, ...}\n",
    "        self.current_time_step = 0\n",
    "        self.done_cnt = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_length_penalty(\n",
    "        self,\n",
    "        length,\n",
    "        alpha=LENGTH_PENALTY,\n",
    "        min_length=MIN_LENGTH,\n",
    "    ):\n",
    "        # Calculate length-penalty,\n",
    "        # because shorter sentence usually have bigger probability.\n",
    "        # In fact, we represent this as log-probability, which is negative value.\n",
    "        # Thus, we need to multiply bigger penalty for shorter one.\n",
    "        p = ((min_length + 1) / (min_length + length))**alpha\n",
    "        # 6/(5+1)\n",
    "        return p\n",
    "\n",
    "\n",
    "\n",
    "    def is_done(self):\n",
    "        '''\n",
    "        빔사이즈보다, done_cnt가 크거나 같으면 1을 리턴, 아니면 0을 리턴.   \n",
    "        done_cnt는 collect_result에서 업데이트 될것.     \n",
    "        '''\n",
    "\n",
    "        # Return 1, if we had EOS more than 'beam_size'-times.\n",
    "        if self.done_cnt >= self.beam_size:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "    def get_batch(self):\n",
    "        '''\n",
    "        returning [beam_size,1] : last step output(V_t)\n",
    "                [baem_size, L, H] : prev_state_i  = 이거 튜플임.\n",
    "        '''\n",
    "        y_hat = self.word_indice[-1].unsqueeze(-1)\n",
    "            # word_indice : tensor([0,0,0,0,0]) 이전 타임 스탭의 출력물을 가져옴. -> unsqueeze(-1) : [5,1]\n",
    "        # |y_hat| = (beam_size, 1)\n",
    "        # if model != transformer:\n",
    "        #     |hidden| = |cell| = (n_layers, beam_size, hidden_size)\n",
    "        #     |h_t_tilde| = (beam_size, 1, hidden_size) or None\n",
    "        # else:\n",
    "        #     |prev_state_i| = (beam_size, length, hidden_size),\n",
    "        #     where i is an index of layer.\n",
    "        return y_hat, self.prev_status\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #@profile \n",
    "    def collect_result(self, y_hat, prev_status):\n",
    "        # |y_hat| = (beam_size, 1, output_size)\n",
    "        # prev_status is a dict, which has following keys:\n",
    "        # if model != transformer:\n",
    "        #     |hidden| = |cell| = (n_layers, beam_size, hidden_size)\n",
    "        #     |h_t_tilde| = (beam_size, 1, hidden_size)\n",
    "        # else:\n",
    "        #     |prev_state_i| = (beam_size, length, hidden_size),\n",
    "        #     where i is an index of layer.\n",
    "        output_size = y_hat.size(-1)\n",
    "\n",
    "        self.current_time_step += 1\n",
    "\n",
    "        #---------------- Calculate cumulative log-probability. ----------------------\n",
    "        # First, fill -inf value to last cumulative probability, if the beam is already finished.\n",
    "        # Second, expand -inf filled cumulative probability to fit to 'y_hat'.\n",
    "        # (beam_size) --> (beam_size, 1, 1) --> (beam_size, 1, output_size)\n",
    "        # Third, add expanded cumulative probability to 'y_hat'\n",
    "        cumulative_prob = self.cumulative_probs[-1].masked_fill_(self.masks[-1], -float('inf'))\n",
    "            # cumulative_probs들이 5개씩 탁탁탁 쌓일텐데 그중 마지막걸 가져와서\n",
    "            # 마지막 마스킹 정보를 갖고와서, True이면 마스크를 하고 with -inf로, 아니면 마스킹을 하지 않는다.\n",
    "        cumulative_prob = y_hat + cumulative_prob.view(-1, 1, 1).expand(self.beam_size, 1, output_size) # broadcasting되기 때문에 expand안해도됨.\n",
    "        # |cumulative_prob| = (beam_size, 1, output_size)\n",
    "\n",
    "        # Now, we have new top log-probability and its index.\n",
    "        # We picked top index as many as 'beam_size'.\n",
    "        # Be aware that we picked top-k from whole batch through 'view(-1)'.\n",
    "\n",
    "        # Following lines are using torch.topk, which is slower than torch.sort.\n",
    "        # top_log_prob, top_indice = torch.topk(\n",
    "        #     cumulative_prob.view(-1), # (beam_size * output_size,)\n",
    "        #     self.beam_size,\n",
    "        #     dim=-1,\n",
    "        # )\n",
    "\n",
    "        # Following lines are using torch.sort, instead of using torch.topk.\n",
    "        top_log_prob, top_indice = cumulative_prob.view(-1).sort(descending=True)\n",
    "            # torch.sort를 사용하면 : values, indice두개를 내뱉는다.\n",
    "        top_log_prob, top_indice = top_log_prob[:self.beam_size], top_indice[:self.beam_size]\n",
    "            # 상위 5개만 갖고온다.\n",
    "\n",
    "        # |top_log_prob| = (beam_size,)\n",
    "        # |top_indice| = (beam_size,)\n",
    "\n",
    "        # Because we picked from whole batch, original word index should be calculated again.\n",
    "        self.word_indice += [top_indice.fmod(output_size)]\n",
    "            # fmod : element-wise나머지 구하기. // devided by output_size\n",
    "            # outputsize로 나누면 원래 vocab_index가 리턴이 되겠네\n",
    "        # Also, we can get an index of beam, which has top-k log-probability search result.\n",
    "        self.beam_indice += [top_indice.div(float(output_size)).long()]\n",
    "            # 41030 -> 4번째 빔에서, 1030번째 단어. 여기서 구하고자 하는것은 몇번째 빔인지 구하고 싶음.\n",
    "\n",
    "        # Add results to history boards.\n",
    "        self.cumulative_probs += [top_log_prob]\n",
    "        self.masks += [torch.eq(self.word_indice[-1], 2)] # Set finish mask if we got EOS.\n",
    "            # torch equal (word_indice[-1], data_loader.EOS) -> 1 if it is, else 0\n",
    "        # Calculate a number of finished beams.\n",
    "        self.done_cnt += self.masks[-1].float().sum() # EOS가 몇개 있엇는지 확인\n",
    "\n",
    "        # In beam search procedure, we only need to memorize latest status.\n",
    "        # For seq2seq, it would be lastest hidden and cell state, and h_t_tilde.\n",
    "        # The problem is hidden(or cell) state and h_t_tilde has different dimension order.\n",
    "        # In other words, a dimension for batch index is different.\n",
    "        # Therefore self.batch_dims stores the dimension index for batch index.\n",
    "        # For transformer, lastest status is each layer's decoder output from the biginning.\n",
    "        # Unlike seq2seq, transformer has to memorize every previous output for attention operation.\n",
    "        for prev_status_name, prev_status in prev_status.items():\n",
    "            self.prev_status[prev_status_name] = torch.index_select(\n",
    "                prev_status,\n",
    "                dim=self.batch_dims[prev_status_name], # 어떤 차원을 뽑아올지\n",
    "                index=self.beam_indice[-1] # 정해진 dim에서 몇번째 데이터를 뽑아올지.\n",
    "            ).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_n_best(self, n=1, length_penalty=.2):\n",
    "        '''\n",
    "        output : 최고의 확률을 갖는 5개를 선별하고, \n",
    "        sentences와 probs를 return한다.\n",
    "\n",
    "        sentences : [[2021, 3, 1394, ...],\n",
    "                    [3019, ,20, 391, ...],\n",
    "                    ...\n",
    "                    [1010, 50, 0203, ...]]\n",
    "\n",
    "        probs : [0.3, 0.5, 0.1, 0.3, 0.4]\n",
    "\n",
    "        '''\n",
    "\n",
    "        sentences, probs, founds = [], [], []\n",
    "\n",
    "        for t in range(len(self.word_indice)):  # for each time-step,,,\n",
    "            # word_indice : [[0,0,0,0,0],[1,0,0,0,0],[1,0,0,0,0],...]\n",
    "            for b in range(self.beam_size):  # for each beam, // 5번\n",
    "                if self.masks[t][b] == 1:  # if we had EOS on this time-step and beam, EOS를 찾으면,\n",
    "                    # Take a record of penaltified log-proability.\n",
    "                    probs += [self.cumulative_probs[t][b] * self.get_length_penalty(t, alpha=length_penalty)]\n",
    "                    founds += [(t, b)] # 어디서 EOS를 찾았는지 -> 그 확률이 어떻게 되나 나중에 역추적할라고\n",
    "                    # 재수가 없으면 EOS없이 max len으로 끝날수 있음.\n",
    "\n",
    "        # Also, collect log-probability from last time-step, for the case of EOS is not shown.\n",
    "        for b in range(self.beam_size):\n",
    "            if self.cumulative_probs[-1][b] != -float('inf'): # If this beam does not have EOS,\n",
    "                if not (len(self.cumulative_probs) - 1, b) in founds:\n",
    "                    probs += [self.cumulative_probs[-1][b] * self.get_length_penalty(len(self.cumulative_probs),\n",
    "                                                                                     alpha=length_penalty)]\n",
    "                    founds += [(t, b)]\n",
    "\n",
    "        # Sort and take n-best.\n",
    "        sorted_founds_with_probs = sorted(\n",
    "            zip(founds, probs),\n",
    "            key=itemgetter(1),\n",
    "            reverse=True,\n",
    "        )[:n]\n",
    "        probs = []\n",
    "\n",
    "        for (end_index, b), prob in sorted_founds_with_probs:\n",
    "            sentence = []\n",
    "\n",
    "            # Trace from the end.\n",
    "            for t in range(end_index, 0, -1):\n",
    "                sentence = [self.word_indice[t][b]] + sentence\n",
    "                b = self.beam_indice[t][b] # 빔따라서 거꾸로 올라감.\n",
    "\n",
    "            sentences += [sentence]\n",
    "            probs += [prob]\n",
    "\n",
    "        return sentences, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "76806b62-73bb-4398-9574-99324e80ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _generate_mask( x, length):\n",
    "    '''\n",
    "\n",
    "    에) length : [4,3,2]\n",
    "    '''\n",
    "    mask = []\n",
    "\n",
    "    max_length = max(length)\n",
    "    for l in length:\n",
    "        if max_length - l > 0:\n",
    "            # If the length is shorter than maximum length among samples,\n",
    "            # set last few values to be 1s to remove attention weight.\n",
    "            mask += [torch.cat([x.new_ones(1, l).zero_(),\n",
    "                                x.new_ones(1, (max_length - l))\n",
    "                                ], dim=-1)]\n",
    "        else:\n",
    "            # If length of sample equals to maximum length among samples,\n",
    "            # set every value in mask to be 0.\n",
    "            mask += [x.new_ones(1, l).zero_()]\n",
    "\n",
    "    mask = torch.cat(mask, dim=0).bool()\n",
    "    # |mask| = (batch_size, max_length)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "x = [torch.randn(64,20,100), torch.randint(20,[64])]\n",
    "\n",
    "batch_size = x[0].size(0)\n",
    "n_dec_layers = 10\n",
    "\n",
    "decoder = nn.Sequential(*[nn.Linear(100,100) for _ in range(n_dec_layers)])\n",
    "\n",
    "mask = _generate_mask(x[0], x[1])\n",
    "# |mask| = (batch_size, n)\n",
    "x = x[0]\n",
    "\n",
    "mask_enc = mask.unsqueeze(1).expand(mask.size(0), x.size(1), mask.size(-1))\n",
    "mask_dec = mask.unsqueeze(1)\n",
    "# |mask_enc| = (batch_size, n, n)\n",
    "# |mask_dec| = (batch_size, 1, n)\n",
    "\n",
    "z = torch.randn(64, 20, 100)\n",
    "# |z| = (batch_size, n, hidden_size)\n",
    "# --------------------여기까지 search 함수와 똑같음 --------------------------\n",
    "\n",
    "\n",
    "prev_status_config = {}\n",
    "for layer_index in range(n_dec_layers + 1):\n",
    "    prev_status_config['prev_state_%d' % layer_index] = {\n",
    "        'init_status': None,\n",
    "        'batch_dim_index': 0,\n",
    "    }\n",
    "    \n",
    "    \n",
    "boards = [\n",
    "    SingleBeamSearchBoard(\n",
    "        z.device,\n",
    "        prev_status_config,\n",
    "        beam_size=beam_size,\n",
    "        max_length=max_length,\n",
    "    ) for _ in range(batch_size)\n",
    "]\n",
    "done_cnt = [board.is_done() for board in boards]\n",
    "\n",
    "length = 0\n",
    "\n",
    "while sum(done_cnt) < batch_size and length <= max_length:\n",
    "    fab_input, fab_z, fab_mask = [],[],[]\n",
    "    fab_prevs = [[] for _ in range(n_dec_layers + 1)]\n",
    "    \n",
    "    \n",
    "    for i, board in enumerate(boards):\n",
    "        if board.is_done() == 0:\n",
    "            y_hat_i, prev_status = board.get_batch()\n",
    "            \n",
    "            fab_input += [y_hat_i]\n",
    "            fab_z += [z[i].unsqueeze(0)]*beam_size\n",
    "            fab_mask += [mask_dec[i].unsqueeze(0)]*beam_size\n",
    "            \n",
    "            for layer_index in range(n_dec_layers + 1):\n",
    "                prev_i = prev_status['prev_state_%d' % layer_index]\n",
    "                if prev_i is not None:\n",
    "                    fab_prevs[layer_index] += [prev_i]\n",
    "                else:\n",
    "                    fab_prevs[layer_index] = None\n",
    "    fab_input = torch.cat(fab_input, dim=0)\n",
    "    fab_z     = torch.cat(fab_z,     dim=0)\n",
    "    fab_mask  = torch.cat(fab_mask,  dim=0)\n",
    "    for i, fab_prev in enumerate(fab_prevs): # i == layer_index\n",
    "        if fab_prev is not None:\n",
    "            fab_prevs[i] = torch.cat(fab_prev, dim=0)\n",
    "            \n",
    "    h_t = fab_input.unsqueeze(-1).expand(*fab_input.size(), 100)\n",
    "    h_t = torch.randn(320,1,100)\n",
    "    \n",
    "    if fab_prevs[0] is None:\n",
    "        fab_prevs[0] = h_t\n",
    "    else:\n",
    "        fab_prevs[0] = torch.cat([fab_prevs[0], h_t], dim = 1)\n",
    "        \n",
    "    for layer_index, block in enumerate(decoder._modules.values()):\n",
    "        prev = fab_prevs[layer_index]\n",
    "        \n",
    "        h_t = block(h_t)\n",
    "        \n",
    "        if fab_prevs[layer_index + 1] is None:\n",
    "            fab_prevs[layer_index + 1] = h_t\n",
    "        else:\n",
    "            fab_prevs[layer_index + 1] = torch.cat([fab_prevs[layer_index + 1], h_t], dim = 1)\n",
    "            \n",
    "    \n",
    "#     y_hat_t = generator(h_t)\n",
    "    y_hat_t = torch.randn(320, 1, 100)\n",
    "    \n",
    "    cnt = 0\n",
    "    for board in boards:\n",
    "        if board.is_done() == 0:\n",
    "            begin = cnt*beam_size\n",
    "            end = begin + beam_size\n",
    "            \n",
    "            prev_status = {}\n",
    "            for layer_index in range(n_dec_layers + 1):\n",
    "                prev_status['prev_state_%d' % layer_index] = fab_prevs[layer_index][begin:end]\n",
    "                \n",
    "            board.collect_result(y_hat_t[begin:end], prev_status)\n",
    "            \n",
    "            cnt += 1\n",
    "            \n",
    "    done_cnt = [board.is_done() for board in boards]\n",
    "    length += 1\n",
    "    \n",
    "    if length == 20:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40ea6199-a380-4e2d-a8d3-0bb067229aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 20, 100])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fab_prevs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "187ea87d-730d-4082-a7f3-fc4fb14062c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board.is_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "997608b4-841d-4ce6-b838-f4098a4b013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[]]\n",
    "\n",
    "for i in range(3):\n",
    "    a[0] += torch.randn(64,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "78fd472a-202a-4e99-8eda-c2f7b261695a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20, 100])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board.get_batch()[1]['prev_state_0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d7fdb74c-bb3f-469e-9971-d6bbcb7ad9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8279, -0.2189, -0.3758,  ..., -1.0492, -0.2075, -0.1194],\n",
       "         [ 0.5449, -0.4042,  0.7085,  ..., -1.5870,  0.2523,  1.5955],\n",
       "         [-1.2392,  0.2312, -2.3776,  ..., -0.4245,  1.4392, -0.0119],\n",
       "         ...,\n",
       "         [-0.5817, -1.4574, -0.9687,  ...,  0.8331,  0.0382,  1.8559],\n",
       "         [ 0.2154, -2.1307, -0.4138,  ..., -0.6675, -0.9962, -0.7747],\n",
       "         [-0.8420,  0.5955, -0.6288,  ..., -1.0931, -0.5311, -1.2907]],\n",
       "\n",
       "        [[ 1.1565, -1.1198, -0.9311,  ...,  0.8487,  1.5364, -1.0445],\n",
       "         [ 0.8156, -1.6106,  0.7313,  ...,  0.4643,  1.3690,  1.3075],\n",
       "         [ 0.6905,  0.9609,  2.2514,  ..., -0.8298,  0.1296, -0.5510],\n",
       "         ...,\n",
       "         [-0.3318,  1.1115,  0.2640,  ...,  1.2754,  0.8217, -0.0123],\n",
       "         [-0.0852,  0.4577,  0.8864,  ..., -0.7627, -0.3184, -0.9649],\n",
       "         [-0.1376,  0.8702, -0.0674,  ..., -0.0086,  0.0292,  1.4140]],\n",
       "\n",
       "        [[-1.4239,  1.2559, -0.0205,  ..., -1.4270,  1.9788, -0.6371],\n",
       "         [-0.1323, -0.7480,  1.4446,  ...,  0.4461,  2.8257, -0.5872],\n",
       "         [-0.3880, -0.2196, -0.2413,  ...,  0.3922,  0.0375, -0.3005],\n",
       "         ...,\n",
       "         [-0.8838,  0.1984, -0.2771,  ...,  0.0632, -0.0805,  1.3488],\n",
       "         [-0.0228,  0.5214, -0.2073,  ...,  0.6497,  0.4110, -0.6869],\n",
       "         [ 0.0961, -0.7035,  1.1320,  ..., -0.0366, -0.1595, -0.1457]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3245, -1.3385,  0.3000,  ..., -1.1350, -0.8225, -0.2329],\n",
       "         [ 0.4695, -0.6143, -0.4530,  ...,  0.4683,  1.6705,  0.8878],\n",
       "         [-0.3964, -1.3081, -1.2608,  ..., -0.8501, -1.1779,  0.9851],\n",
       "         ...,\n",
       "         [-0.8444,  0.0436, -0.0653,  ..., -1.2414, -1.0947,  0.2720],\n",
       "         [ 0.3946,  1.2918,  2.4390,  ...,  0.4795,  0.6690,  0.1636],\n",
       "         [-0.8540, -0.1770,  0.4523,  ..., -1.6438, -0.3393, -0.3629]],\n",
       "\n",
       "        [[-0.5301,  0.0505,  0.9090,  ..., -0.8909, -0.9174,  1.0673],\n",
       "         [-0.5176,  0.3483,  1.2260,  ...,  0.0309,  0.7636,  0.2497],\n",
       "         [-0.9316,  0.2748,  0.6693,  ...,  0.3473, -0.0744,  1.9796],\n",
       "         ...,\n",
       "         [-2.4961, -0.2855,  0.4765,  ...,  0.0962, -0.8689, -0.8747],\n",
       "         [ 0.8887,  0.3272,  0.1748,  ...,  1.1374, -0.3418,  0.9778],\n",
       "         [-1.3203, -1.0586,  1.3694,  ..., -0.4913, -0.8945,  1.3010]],\n",
       "\n",
       "        [[-0.4728,  0.9368,  0.3158,  ..., -0.1385,  0.8083,  0.1791],\n",
       "         [-0.4351,  0.3505,  0.1066,  ..., -1.0855, -1.2594,  0.4463],\n",
       "         [ 0.0036, -0.2582, -0.7430,  ...,  0.7714, -0.4896, -0.1545],\n",
       "         ...,\n",
       "         [ 0.0241, -0.6614, -1.2239,  ...,  0.7094,  1.5815, -0.5156],\n",
       "         [ 0.0254,  0.7802, -2.0692,  ..., -0.2032,  1.4311,  1.9876],\n",
       "         [ 0.7197,  2.9381, -0.5344,  ..., -0.4010, -0.5334, -0.1458]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = nn.LayerNorm(100)\n",
    "aa(torch.randn(320,10,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0737d259-18df-4ad3-b9b5-022872d04144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 20, 100])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f3cb159-5989-4d18-be6a-1db1c52f3164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 20, 100])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fab_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b96ea2b9-95f0-453e-9266-827eb7afaaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20, 100])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([z[0].unsqueeze(0)]*5, dim = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516254e9-2d33-4032-a221-4496726db235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10841a6-8e71-4829-b60b-5b59f5587412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "116ce4ab-dd5a-4a32-aa8d-61bde4186cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., -inf, -inf, -inf, -inf])]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_probs = [torch.FloatTensor([.0] + [-float('inf')]*(beam_size - 1))]\n",
    "cumulative_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1314a048-8786-4224-b640-4f45cf9e206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., -inf, -inf, -inf, -inf])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = 10000\n",
    "y_hat = torch.randn(5,1,10000)\n",
    "masks = [torch.tensor([0,0,0,0,0]).bool()]\n",
    "\n",
    "cumulative_prob = cumulative_probs[-1].masked_fill_(masks[-1], -float('inf'))\n",
    "cumulative_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "02b1ce29-acf5-4547-813f-7380fdef4402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 10000])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob = y_hat + cumulative_prob.view(-1,1,1).expand(5,1,output_size)\n",
    "cumulative_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1aa5a1b3-6751-4d98-aded-feb875859614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5879,  0.7067,  0.7412,  ...,  0.6248, -0.5969, -0.9310]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]],\n",
       "\n",
       "        [[   -inf,    -inf,    -inf,  ...,    -inf,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80f9565c-9fea-4b12-bbb8-4bf982cbc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_log_prob, top_indice = cumulative_prob.view(-1).sort(descending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8224a2da-5ab8-4b37-9a34-967287e03a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6192, 3.3950, 3.3080,  ...,   -inf,   -inf,   -inf])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c345a80-6a1b-451b-bbad-a4150796de4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2534,  7517,  9918,  ..., 49997, 49998, 49999])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1af399f3-e81d-49a0-9fb8-92e5581bf6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., -inf, -inf, -inf, -inf])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5ef1bd8d-6b1f-4316-8ff3-850dbb0c3e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3cf7533d-987c-45b8-8e45-ef1377e167ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9862, 1.3751, 0.0278, 0.4193],\n",
       "        [0.9862, 1.3751, 0.0278, 0.4193]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "indices = torch.tensor([0,0])\n",
    "torch.index_select(x, 0, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e64ca-1930-41a2-a95a-6b862ce3aa65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
