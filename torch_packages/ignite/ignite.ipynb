{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7390143-0e3f-4813-845b-6871b027b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# torch quickStart : \n",
    "https://colab.research.google.com/github/pytorch/ignite/blob/master/examples/notebooks/FashionMNIST.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e22efae-c3c0-455f-9e3c-d484c32e7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignite 예제\n",
    "\n",
    "# class MyDataset(Dataset):\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#           return {\n",
    "#                  \"image\": self.images[i],\n",
    "#                  \"label\": self.labels[i],\n",
    "#                  \"path\": self.paths[i],\n",
    "#           }\n",
    "\n",
    "# # A batch from the dataloader will be something like\n",
    "# #  batch['image'].shape = (4, 3, 224, 224)\n",
    "# #  batch['label'].shape = (4, )\n",
    "\n",
    "# def update_fn(engine, batch):\n",
    "#     model.train()\n",
    "#     x = batch['image'].cuda()\n",
    "#     y = batch['label'].cuda()\n",
    "#     y_pred = model(x)\n",
    "#     optimizer.zero_grads()\n",
    "#     loss = criterion(y_pred, y)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     return loss.item()\n",
    "\n",
    "\n",
    "# trainer = Engine(update_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3bc8adc-05b6-49d4-b885-61bb564d4212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8423125-c849-45f5-864c-84ec7f258e69",
   "metadata": {},
   "source": [
    "`Ignite` is a High-level library to help with training neural networks in PyTorch. It comes with an `Engine` to setup a training loop, various metrics, handlers and a helpful contrib section! \n",
    "\n",
    "Below we import the following:\n",
    "* **Engine**: Runs a given process_function over each batch of a dataset, emitting events as it goes.\n",
    "* **Events**: Allows users to attach functions to an `Engine` to fire functions at a specific event. Eg: `EPOCH_COMPLETED`, `ITERATION_STARTED`, etc.\n",
    "* **Accuracy**: Metric to calculate accuracy over a dataset, for binary, multiclass, multilabel cases. \n",
    "* **Loss**: General metric that takes a loss function as a parameter, calculate loss over a dataset.\n",
    "* **RunningAverage**: General metric to attach to Engine during training. \n",
    "* **ModelCheckpoint**: Handler to checkpoint models. \n",
    "* **EarlyStopping**: Handler to stop training based on a score function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b3af218-7818-4c5d-9a5e-2b6deb86a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a6b051-100c-431c-9969-f97efe3b2c09",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8f4557b-9e25-4f75-889a-1d70d017d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfea4748156457b92eb14deae64fcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b18e501188481880661d7f4f77896b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cd1dd405a44f1aa36d69193fda1ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8733baf30a1344b389d1d8bfa3baaab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rainism/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-4gogm3_o/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "validationset = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
    "val_loader = DataLoader(validationset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c981032-13c3-4540-a7c6-11aaac52174b",
   "metadata": {},
   "source": [
    "## simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2f6d78d-8f22-4a00-99f9-bc763d3af3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.convlayer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*6*6,600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer2(x)\n",
    "        x = x.view(-1,64*6*6)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dda8a39d-733f-43c8-b186-bf9b39d57d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model,and defining optimizer and loss\n",
    "model = CNN()\n",
    "# moving model to gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4eb99-2f52-4d5c-8a49-7f2ee2316bca",
   "metadata": {},
   "source": [
    "---\n",
    "# ignite starts from here\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ecc33c-fcf4-40a7-b175-d0945969a4ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Instantiating Training and Evaluating Engines\n",
    "\n",
    "Below we create 3 engines, \n",
    "- a trainer, \n",
    "- an evaluator for the training set\n",
    "- an evaluator for the validation set, \n",
    "by using the `create_supervised_trainer` and `create_supervised_evaluator` and passing the required arguments.\n",
    "\n",
    "\n",
    "We import the metrics from `ignite.metrics` which we want to calculate for the model. \n",
    "- Like `Accuracy`, `ConfusionMatrix`, and `Loss` \n",
    "- we pass them to `evaluator` engines which will calculate these metrics for each iteration.\n",
    "\n",
    "* `training_history`: it stores the training loss and accuracy\n",
    "* `validation_history`:it stores the validation loss and accuracy\n",
    "* `last_epoch`: it stores the last epoch untill the model is trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bd18ab4-7d44-4119-828b-f52394be0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "epochs = 12\n",
    "\n",
    "# ignite.engine : trainer\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "\n",
    "# ignite.metrics로 부터 파생\n",
    "metrics = {\n",
    "    'accuracy':Accuracy(),\n",
    "    'nll':Loss(criterion),\n",
    "    'cm':ConfusionMatrix(num_classes=10)\n",
    "}\n",
    "\n",
    "# ignite.engine : evaluator\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device) # optimizer, criterion이 없고, metrics가 들어감.\n",
    "\n",
    "# ignite.engine : evaluator\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "training_history = {'accuracy':[],'loss':[]}\n",
    "validation_history = {'accuracy':[],'loss':[]}\n",
    "\n",
    "last_epoch = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1e09a-70e5-44c1-bc88-c893cf2a4012",
   "metadata": {},
   "source": [
    "To start, we will attach a metric of `RunningAverage` to track a running average of the scalar loss output for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a75b616-37fa-4eb2-aa9a-d20ab273e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
    "# 어케 쓰는건지 잘 모르겠음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d19c6e-0121-4f62-a8c9-b9dc05685e7d",
   "metadata": {},
   "source": [
    "### EarlyStopping - Tracking Validation Loss\n",
    "\n",
    "Now we will setup a `EarlyStopping` handler for this training process. \\\n",
    "EarlyStopping requires a score_function that allows the user to define whatever criteria to stop trainig. \\\n",
    "In this case, if the loss of the validation set does not decrease in 10 epochs, the training process will stop early.\\\n",
    "Since the `EarlyStopping` handler relies on the validation loss, it's attached to the `val_evaluator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56013e47-0bcd-46f9-b475-0c93e12e2d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x17d80aa60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['nll'] # negative log likelihood\n",
    "    return -val_loss\n",
    "\n",
    "# earlystopping조건을 설정하고\n",
    "handler = EarlyStopping(patience=10, score_function=score_function, trainer=trainer) # 여기서 trainer가 engine임.\n",
    "# handler(earlystopping)조건이 발생시 events를 stop한다.\n",
    "val_evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "\n",
    "'''\n",
    "순서\n",
    "   - 1. epochs started\n",
    "   - 2. iteration completed \n",
    "   - 3. iteration started\n",
    "   - 4. iteration completed\n",
    "   - 5. epochs completed\n",
    "   \n",
    "https://pytorch.org/ignite/v0.4.6/concepts.html#handlers\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4acab63-fb34-4785-8738-4d16f1dca1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.Engine at 0x17d867190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer # trainer 가 engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf193cf-a36d-4c85-80f1-93fad04c15e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b71bdd8-ce60-4911-bf2a-49f6f6f51293",
   "metadata": {},
   "source": [
    "### Attaching Custom Functions to Engine at specific Events\n",
    "\n",
    "Below you will see ways to define your own custom functions and attaching them to various `Events` of the training process.\n",
    "\n",
    "The functions below both achieve similar tasks, they print the results of the evaluator run on a dataset. One function does that on the training evaluator and dataset, while the other on the validation. Another difference is how these functions are attached in the trainer engine.\n",
    "\n",
    "The first method involves using a decorator, the syntax is simple \n",
    "- `@` `trainer.on(Events.EPOCH_COMPLETED)`, means that the decorated function will be attached to the trainer and called at the end of each epoch. \n",
    "\n",
    "The second method involves using the add_event_handler method of trainer \n",
    "- `trainer.add_event_handler(Events.EPOCH_COMPLETED, custom_function)`. This achieves the same result as the above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4999c05-1151-429a-a303-0be4197ea315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x285f06df0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainer에서 epoch가 끝날때(Events.EPOCH_COMPLETED)\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    train_evaluator.run(train_loader)\n",
    "        # train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "        # train_loader = DataLoader\n",
    "    metrics = train_evaluator.state.metrics # store metrics 정보 to Engine by calculation\n",
    "    accuracy = metrics['accuracy']*100\n",
    "    loss = metrics['nll']\n",
    "    last_epoch.append(0)\n",
    "    training_history['accuracy'].append(accuracy)\n",
    "    training_history['loss'].append(loss)\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, accuracy, loss))\n",
    "\n",
    "def log_validation_results(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    accuracy = metrics['accuracy']*100\n",
    "    loss = metrics['nll']\n",
    "    validation_history['accuracy'].append(accuracy)\n",
    "    validation_history['loss'].append(loss)\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, accuracy, loss))\n",
    "    \n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089e7c8-5dca-4b0b-bbe8-64f0f01f8260",
   "metadata": {},
   "source": [
    "## ignite.Engine.state \n",
    "is introduced in Engine to store the output of the process_function, current epoch, iteration and other helpful information. \\\n",
    "Each Engine contains a State, which includes the following:\n",
    "\n",
    "- state.iteration         # 1-based, the first iteration is 1\n",
    "- state.epoch             # 1-based, the first epoch is 1\n",
    "- state.seed              # seed to set at each epoch\n",
    "- state.dataloader        # data passed to engine\n",
    "- state.epoch_length      # optional length of an epoch\n",
    "- state.max_epochs        # number of epochs to run\n",
    "- state.batch             # batch passed to `process_function`\n",
    "- state.output            # output of `process_function` after a single iteration\n",
    "- state.metrics           # dictionary with defined metrics if any\n",
    "- state.times             # dictionary with total and per-epoch times fetched on keys: Events.EPOCH_COMPLETED.name and Events.COMPLETED.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f6e99a2-3e54-43f8-9e18-38704eeae429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch가 끝날때 할 행동\n",
    "@trainer.on(Events.COMPLETED)\n",
    "def log_confusion_matrix(trainer):\n",
    "    val_evaluator.run(val_loader)\n",
    "    metrics = val_evaluator.state.metrics\n",
    "    cm = metrics['cm']\n",
    "    cm = cm.numpy()\n",
    "    cm = cm.astype(int)\n",
    "    classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']\n",
    "    fig, ax = plt.subplots(figsize=(10,10))  \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax,fmt=\"d\")\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix') \n",
    "    ax.xaxis.set_ticklabels(classes,rotation=90)\n",
    "    ax.yaxis.set_ticklabels(classes,rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9eb86721-4df9-4219-a7b2-c13d6d8fcefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x16852eca0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('./saved_models', 'fashionMNIST', n_saved=2, create_dir=True, save_as_state_dict=True, require_empty=False)\n",
    "    # https://pytorch.org/ignite/generated/ignite.handlers.checkpoint.ModelCheckpoint.html\n",
    "    # (dirname, filename_prefix, save_interval, ...)\n",
    "    # save_as_state_dict?, require_empty?\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'fashionMNIST': model})\n",
    "    # 세번째 파라미터는 args인데,, 흠 pass args to handler?라는데 Handler??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01f19c34-6232-49ba-bff5-ed1f5a0321a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jk/t5vx8lsx1fs7nd9c58w611bh0000gn/T/ipykernel_4416/702884084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/ignite/engine/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b510a1-8c85-41e6-8d4f-d6ae83758aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044cb5e-68d6-44ed-ba13-9e5ce6c15b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "629f289f-0599-4eac-85c6-e563ef15e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.convlayer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(64*6*6,600)\n",
    "        self.drop = nn.Dropout2d(0.25)\n",
    "        self.fc2 = nn.Linear(600, 120)\n",
    "        self.fc3 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer2(x)\n",
    "        x = x.view(-1,64*6*6)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbedb775-c1b3-4b9d-bf05-b822faf630c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model,and defining optimizer and loss\n",
    "model = CNN()\n",
    "# moving model to gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234ff8e-4780-4281-95cf-dcbabcf2d02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "epochs = 12\n",
    "# creating trainer,evaluator\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "metrics = {\n",
    "    'accuracy':Accuracy(),\n",
    "    'nll':Loss(criterion),\n",
    "    'cm':ConfusionMatrix(num_classes=10)\n",
    "}\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "training_history = {'accuracy':[],'loss':[]}\n",
    "validation_history = {'accuracy':[],'loss':[]}\n",
    "last_epoch = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
