{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9e516-9aac-4265-b1b2-3256005d82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.utils import setup_logger\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "\n",
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    '''\n",
    "    전처리\n",
    "    '''\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST(download=True, root=\".\", transform=data_transform, train=True), batch_size=train_batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        MNIST(download=False, root=\".\", transform=data_transform, train=False), batch_size=val_batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    device = \"cpu\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "\n",
    "    model.to(device)  # Move model before creating optimizer\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    criterion = nn.NLLLoss()\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    trainer.logger = setup_logger(\"trainer\")\n",
    "\n",
    "    val_metrics = {\"accuracy\": Accuracy(), \"nll\": Loss(criterion)}\n",
    "    evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "    evaluator.logger = setup_logger(\"evaluator\")\n",
    "\n",
    "    pbar = tqdm(initial=0, leave=False, total=len(train_loader), desc=f\"ITERATION - loss: {0:.2f}\")\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "    def log_training_loss(engine):\n",
    "        pbar.desc = f\"ITERATION - loss: {engine.state.output:.2f}\"\n",
    "        pbar.update(log_interval)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        pbar.refresh()\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics[\"accuracy\"]\n",
    "        avg_nll = metrics[\"nll\"]\n",
    "        tqdm.write(\n",
    "            f\"Training Results - Epoch: {engine.state.epoch} Avg accuracy: {avg_accuracy:.2f} Avg loss: {avg_nll:.2f}\"\n",
    "        )\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics[\"accuracy\"]\n",
    "        avg_nll = metrics[\"nll\"]\n",
    "        tqdm.write(\n",
    "            f\"Validation Results - Epoch: {engine.state.epoch} Avg accuracy: {avg_accuracy:.2f} Avg loss: {avg_nll:.2f}\"\n",
    "        )\n",
    "\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED | Events.COMPLETED)\n",
    "    def log_time(engine):\n",
    "        tqdm.write(f\"{trainer.last_event_name.name} took { trainer.state.times[trainer.last_event_name.name]} seconds\")\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    pbar.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"input batch size for training (default: 64)\")\n",
    "    parser.add_argument(\n",
    "        \"--val_batch_size\", type=int, default=1000, help=\"input batch size for validation (default: 1000)\"\n",
    "    )\n",
    "    parser.add_argument(\"--epochs\", type=int, default=10, help=\"number of epochs to train (default: 10)\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01, help=\"learning rate (default: 0.01)\")\n",
    "    parser.add_argument(\"--momentum\", type=float, default=0.5, help=\"SGD momentum (default: 0.5)\")\n",
    "    parser.add_argument(\n",
    "        \"--log_interval\", type=int, default=10, help=\"how many batches to wait before logging training status\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run(args.batch_size, args.val_batch_size, args.epochs, args.lr, args.momentum, args.log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f472cf-2721-4b8e-b1b4-1071959235ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1651391413.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/jk/t5vx8lsx1fs7nd9c58w611bh0000gn/T/ipykernel_21686/1651391413.py\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8) # optimizer\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "model = Net() # network\n",
    "train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size # train_dataloader, valid_dataloader\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8) # optimizer\n",
    "criterion = nn.NLLLoss() # loss\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion)\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"nll\": Loss(criterion)\n",
    "}\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "def log_training_loss(trainer):\n",
    "    print(f\"Epoch[{trainer.state.epoch}] Loss: {trainer.state.output:.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Training Results - Epoch: {trainer.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['nll']:.2f}\")\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Results - Epoch: {trainer.state.epoch}  Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['nll']:.2f}\")\n",
    "\n",
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795fc3d-1af7-4796-83c4-494f2c9d9198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0f6e-c73d-4320-93b1-2eed178fed76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
